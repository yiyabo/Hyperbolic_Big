#!/usr/bin/env python3
"""
æ•°æ®ç»Ÿè®¡åˆ†æå™¨
æä¾›å…¨é¢çš„æ•°æ®ç»Ÿè®¡å’Œå¯è§†åŒ–åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import logging
from typing import Dict, List, Tuple
import json

logger = logging.getLogger(__name__)

class DataStatistics:
    """æ•°æ®ç»Ÿè®¡åˆ†æå™¨"""
    
    def __init__(self, output_dir: str = "analysis_results"):
        """åˆå§‹åŒ–ç»Ÿè®¡åˆ†æå™¨"""
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # è®¾ç½®ç»˜å›¾æ ·å¼
        plt.style.use('default')
        sns.set_palette("husl")
    
    def analyze_ppi_network_properties(self, ppi_df: pd.DataFrame) -> Dict:
        """åˆ†æPPIç½‘ç»œçš„åŸºæœ¬å±æ€§"""
        logger.info("åˆ†æPPIç½‘ç»œåŸºæœ¬å±æ€§...")
        
        # åŸºç¡€ç»Ÿè®¡
        stats = {
            'num_interactions': len(ppi_df),
            'num_proteins': len(set(ppi_df['protein1']).union(set(ppi_df['protein2']))),
            'avg_degree': 2 * len(ppi_df) / len(set(ppi_df['protein1']).union(set(ppi_df['protein2']))),
        }
        
        # ç½®ä¿¡åº¦åˆ†æ
        stats['confidence_stats'] = {
            'mean_combined_score': ppi_df['combined_score'].mean(),
            'std_combined_score': ppi_df['combined_score'].std(),
            'min_combined_score': ppi_df['combined_score'].min(),
            'max_combined_score': ppi_df['combined_score'].max(),
            'percentiles': ppi_df['combined_score'].quantile([0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]).to_dict()
        }
        
        # è¯æ®é€šé“åˆ†æ
        evidence_channels = ['neighborhood', 'fusion', 'cooccurence', 'coexpression', 
                           'experimental', 'database', 'textmining']
        
        stats['evidence_analysis'] = {}
        for channel in evidence_channels:
            if channel in ppi_df.columns:
                stats['evidence_analysis'][channel] = {
                    'non_zero_count': (ppi_df[channel] > 0).sum(),
                    'non_zero_percentage': (ppi_df[channel] > 0).mean() * 100,
                    'mean_score': ppi_df[channel].mean(),
                    'max_score': ppi_df[channel].max()
                }
        
        logger.info(f"PPIç½‘ç»œåŸºæœ¬å±æ€§:")
        logger.info(f"  ç›¸äº’ä½œç”¨æ•°: {stats['num_interactions']:,}")
        logger.info(f"  è›‹ç™½è´¨æ•°: {stats['num_proteins']:,}")
        logger.info(f"  å¹³å‡åº¦æ•°: {stats['avg_degree']:.2f}")
        logger.info(f"  å¹³å‡ç½®ä¿¡åº¦: {stats['confidence_stats']['mean_combined_score']:.1f}")
        
        return stats
    
    def analyze_protein_properties(self, protein_df: pd.DataFrame) -> Dict:
        """åˆ†æè›‹ç™½è´¨å±æ€§åˆ†å¸ƒ"""
        logger.info("åˆ†æè›‹ç™½è´¨å±æ€§åˆ†å¸ƒ...")
        
        stats = {
            'num_proteins': len(protein_df),
            'length_distribution': {
                'mean': protein_df['protein_size'].mean(),
                'std': protein_df['protein_size'].std(),
                'min': protein_df['protein_size'].min(),
                'max': protein_df['protein_size'].max(),
                'percentiles': protein_df['protein_size'].quantile([0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]).to_dict()
            }
        }
        
        # ç‰©ç§åˆ†å¸ƒåˆ†æ
        if 'species_id' in protein_df.columns:
            species_counts = protein_df['species_id'].value_counts()
            stats['species_distribution'] = {
                'num_species': len(species_counts),
                'top_10_species': species_counts.head(10).to_dict(),
                'species_with_single_protein': (species_counts == 1).sum(),
                'species_with_100plus_proteins': (species_counts >= 100).sum()
            }
        
        # è´¨é‡åˆ†æ•°åˆ†æ
        if 'quality_score' in protein_df.columns:
            stats['quality_distribution'] = {
                'mean': protein_df['quality_score'].mean(),
                'std': protein_df['quality_score'].std(),
                'min': protein_df['quality_score'].min(),
                'max': protein_df['quality_score'].max(),
                'high_quality_count': (protein_df['quality_score'] >= 0.8).sum(),
                'medium_quality_count': ((protein_df['quality_score'] >= 0.6) & 
                                       (protein_df['quality_score'] < 0.8)).sum(),
                'low_quality_count': (protein_df['quality_score'] < 0.6).sum()
            }
        
        logger.info(f"è›‹ç™½è´¨å±æ€§åˆ†æ:")
        logger.info(f"  è›‹ç™½è´¨æ€»æ•°: {stats['num_proteins']:,}")
        logger.info(f"  å¹³å‡é•¿åº¦: {stats['length_distribution']['mean']:.1f}")
        logger.info(f"  é•¿åº¦èŒƒå›´: {stats['length_distribution']['min']}-{stats['length_distribution']['max']}")
        
        return stats
    
    def plot_ppi_statistics(self, ppi_df: pd.DataFrame, save_plots: bool = True) -> None:
        """ç»˜åˆ¶PPIç½‘ç»œç»Ÿè®¡å›¾è¡¨"""
        logger.info("ç»˜åˆ¶PPIç½‘ç»œç»Ÿè®¡å›¾è¡¨...")
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('PPI Network Statistics', fontsize=16)
        
        # 1. ç½®ä¿¡åº¦åˆ†å¸ƒ
        axes[0,0].hist(ppi_df['combined_score'], bins=50, alpha=0.7, edgecolor='black')
        axes[0,0].set_xlabel('Combined Score')
        axes[0,0].set_ylabel('Frequency')
        axes[0,0].set_title('Confidence Score Distribution')
        axes[0,0].axvline(ppi_df['combined_score'].mean(), color='red', linestyle='--', 
                         label=f'Mean: {ppi_df["combined_score"].mean():.1f}')
        axes[0,0].legend()
        
        # 2. è¯æ®é€šé“ä½¿ç”¨æƒ…å†µ
        evidence_channels = ['neighborhood', 'fusion', 'cooccurence', 'coexpression', 
                           'experimental', 'database', 'textmining']
        available_channels = [ch for ch in evidence_channels if ch in ppi_df.columns]
        
        channel_usage = []
        channel_names = []
        for channel in available_channels:
            usage = (ppi_df[channel] > 0).mean() * 100
            channel_usage.append(usage)
            channel_names.append(channel.capitalize())
        
        axes[0,1].bar(channel_names, channel_usage)
        axes[0,1].set_ylabel('Usage Percentage (%)')
        axes[0,1].set_title('Evidence Channel Usage')
        axes[0,1].tick_params(axis='x', rotation=45)
        
        # 3. åº¦æ•°åˆ†å¸ƒ
        all_proteins = list(ppi_df['protein1']) + list(ppi_df['protein2'])
        degree_counts = pd.Series(all_proteins).value_counts()
        
        axes[0,2].hist(degree_counts.values, bins=50, alpha=0.7, edgecolor='black')
        axes[0,2].set_xlabel('Degree')
        axes[0,2].set_ylabel('Number of Proteins')
        axes[0,2].set_title('Degree Distribution')
        axes[0,2].set_yscale('log')
        axes[0,2].set_xscale('log')
        
        # 4. è¯æ®é€šé“ç›¸å…³æ€§çƒ­å›¾
        if len(available_channels) > 1:
            corr_matrix = ppi_df[available_channels].corr()
            im = axes[1,0].imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)
            axes[1,0].set_xticks(range(len(available_channels)))
            axes[1,0].set_yticks(range(len(available_channels)))
            axes[1,0].set_xticklabels([ch.capitalize() for ch in available_channels], rotation=45)
            axes[1,0].set_yticklabels([ch.capitalize() for ch in available_channels])
            axes[1,0].set_title('Evidence Channel Correlation')
            
            # æ·»åŠ ç›¸å…³ç³»æ•°æ ‡æ³¨
            for i in range(len(available_channels)):
                for j in range(len(available_channels)):
                    axes[1,0].text(j, i, f'{corr_matrix.iloc[i,j]:.2f}', 
                                  ha='center', va='center', fontsize=8)
            
            plt.colorbar(im, ax=axes[1,0])
        
        # 5. ç½®ä¿¡åº¦vsè¯æ®é€šé“æ•£ç‚¹å›¾
        if 'experimental' in ppi_df.columns:
            axes[1,1].scatter(ppi_df['experimental'], ppi_df['combined_score'], 
                            alpha=0.5, s=1)
            axes[1,1].set_xlabel('Experimental Evidence')
            axes[1,1].set_ylabel('Combined Score')
            axes[1,1].set_title('Experimental vs Combined Score')
        
        # 6. ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
        sorted_scores = np.sort(ppi_df['combined_score'])
        cumulative = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores)
        axes[1,2].plot(sorted_scores, cumulative)
        axes[1,2].set_xlabel('Combined Score')
        axes[1,2].set_ylabel('Cumulative Probability')
        axes[1,2].set_title('Cumulative Distribution Function')
        
        plt.tight_layout()
        
        if save_plots:
            plot_path = self.output_dir / "ppi_network_statistics.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            logger.info(f"PPIç»Ÿè®¡å›¾è¡¨å·²ä¿å­˜: {plot_path}")
        
        plt.show()
    
    def plot_protein_statistics(self, protein_df: pd.DataFrame, save_plots: bool = True) -> None:
        """ç»˜åˆ¶è›‹ç™½è´¨ç»Ÿè®¡å›¾è¡¨"""
        logger.info("ç»˜åˆ¶è›‹ç™½è´¨ç»Ÿè®¡å›¾è¡¨...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Protein Statistics', fontsize=16)
        
        # 1. é•¿åº¦åˆ†å¸ƒ
        axes[0,0].hist(protein_df['protein_size'], bins=50, alpha=0.7, edgecolor='black')
        axes[0,0].set_xlabel('Protein Length (amino acids)')
        axes[0,0].set_ylabel('Frequency')
        axes[0,0].set_title('Protein Length Distribution')
        axes[0,0].axvline(protein_df['protein_size'].mean(), color='red', linestyle='--',
                         label=f'Mean: {protein_df["protein_size"].mean():.1f}')
        axes[0,0].legend()
        
        # 2. ç‰©ç§åˆ†å¸ƒ
        if 'species_id' in protein_df.columns:
            species_counts = protein_df['species_id'].value_counts().head(15)
            axes[0,1].bar(range(len(species_counts)), species_counts.values)
            axes[0,1].set_xlabel('Species (Top 15)')
            axes[0,1].set_ylabel('Number of Proteins')
            axes[0,1].set_title('Protein Distribution by Species')
            axes[0,1].set_xticks(range(len(species_counts)))
            axes[0,1].set_xticklabels(species_counts.index, rotation=45)
        
        # 3. è´¨é‡åˆ†æ•°åˆ†å¸ƒ
        if 'quality_score' in protein_df.columns:
            axes[1,0].hist(protein_df['quality_score'], bins=30, alpha=0.7, edgecolor='black')
            axes[1,0].set_xlabel('Quality Score')
            axes[1,0].set_ylabel('Frequency')
            axes[1,0].set_title('Quality Score Distribution')
            axes[1,0].axvline(protein_df['quality_score'].mean(), color='red', linestyle='--',
                             label=f'Mean: {protein_df["quality_score"].mean():.3f}')
            axes[1,0].legend()
        
        # 4. é•¿åº¦vsè´¨é‡åˆ†æ•°æ•£ç‚¹å›¾
        if 'quality_score' in protein_df.columns:
            axes[1,1].scatter(protein_df['protein_size'], protein_df['quality_score'], 
                            alpha=0.5, s=1)
            axes[1,1].set_xlabel('Protein Length')
            axes[1,1].set_ylabel('Quality Score')
            axes[1,1].set_title('Length vs Quality Score')
        
        plt.tight_layout()
        
        if save_plots:
            plot_path = self.output_dir / "protein_statistics.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            logger.info(f"è›‹ç™½è´¨ç»Ÿè®¡å›¾è¡¨å·²ä¿å­˜: {plot_path}")
        
        plt.show()
    
    def generate_comprehensive_report(self, protein_df: pd.DataFrame, 
                                    ppi_df: pd.DataFrame, 
                                    expert_groups: Dict[str, List[str]] = None,
                                    filtering_stats: Dict = None) -> Dict:
        """ç”Ÿæˆç»¼åˆæ•°æ®æŠ¥å‘Š"""
        logger.info("ç”Ÿæˆç»¼åˆæ•°æ®æŠ¥å‘Š...")
        
        report = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'data_summary': {
                'proteins': len(protein_df),
                'interactions': len(ppi_df),
                'unique_proteins_in_network': len(set(ppi_df['protein1']).union(set(ppi_df['protein2'])))
            }
        }
        
        # æ·»åŠ å„ç§ç»Ÿè®¡ä¿¡æ¯
        report['protein_analysis'] = self.analyze_protein_properties(protein_df)
        report['ppi_analysis'] = self.analyze_ppi_network_properties(ppi_df)
        
        # ä¸“å®¶ç»„åˆ†æ
        if expert_groups:
            report['expert_groups_analysis'] = {
                'num_experts': len(expert_groups),
                'total_proteins_in_groups': sum(len(proteins) for proteins in expert_groups.values()),
                'group_sizes': {name: len(proteins) for name, proteins in expert_groups.items()},
                'size_distribution': {
                    'min_size': min(len(proteins) for proteins in expert_groups.values()),
                    'max_size': max(len(proteins) for proteins in expert_groups.values()),
                    'mean_size': np.mean([len(proteins) for proteins in expert_groups.values()]),
                    'std_size': np.std([len(proteins) for proteins in expert_groups.values()])
                }
            }
        
        # è¿‡æ»¤ç»Ÿè®¡ä¿¡æ¯
        if filtering_stats:
            report['filtering_statistics'] = filtering_stats
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self.output_dir / "comprehensive_data_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        logger.info(f"ç»¼åˆæ•°æ®æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # æ‰“å°å…³é”®ç»Ÿè®¡ä¿¡æ¯
        self._print_summary_report(report)
        
        return report
    
    def _print_summary_report(self, report: Dict) -> None:
        """æ‰“å°æ‘˜è¦æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("                      æ•°æ®å¤„ç†æ‘˜è¦æŠ¥å‘Š")
        print("="*80)
        
        # åŸºç¡€æ•°æ®ç»Ÿè®¡
        print(f"\nğŸ“Š åŸºç¡€æ•°æ®ç»Ÿè®¡:")
        print(f"   è›‹ç™½è´¨æ€»æ•°: {report['data_summary']['proteins']:,}")
        print(f"   ç›¸äº’ä½œç”¨æ€»æ•°: {report['data_summary']['interactions']:,}")
        print(f"   ç½‘ç»œä¸­è›‹ç™½è´¨æ•°: {report['data_summary']['unique_proteins_in_network']:,}")
        print(f"   å¹³å‡åº¦æ•°: {2*report['data_summary']['interactions']/report['data_summary']['unique_proteins_in_network']:.2f}")
        
        # è›‹ç™½è´¨å±æ€§
        if 'protein_analysis' in report:
            pa = report['protein_analysis']
            print(f"\nğŸ§¬ è›‹ç™½è´¨å±æ€§:")
            print(f"   å¹³å‡é•¿åº¦: {pa['length_distribution']['mean']:.1f} Â± {pa['length_distribution']['std']:.1f}")
            print(f"   é•¿åº¦èŒƒå›´: {pa['length_distribution']['min']} - {pa['length_distribution']['max']}")
            
            if 'species_distribution' in pa:
                print(f"   ç‰©ç§æ•°é‡: {pa['species_distribution']['num_species']:,}")
            
            if 'quality_distribution' in pa:
                qd = pa['quality_distribution']
                print(f"   å¹³å‡è´¨é‡åˆ†æ•°: {qd['mean']:.3f}")
                print(f"   é«˜è´¨é‡è›‹ç™½è´¨: {qd['high_quality_count']:,} ({qd['high_quality_count']/report['data_summary']['proteins']*100:.1f}%)")
        
        # PPIç½‘ç»œå±æ€§
        if 'ppi_analysis' in report:
            ppi = report['ppi_analysis']
            print(f"\nğŸ”— PPIç½‘ç»œå±æ€§:")
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {ppi['confidence_stats']['mean_combined_score']:.1f}")
            print(f"   ç½®ä¿¡åº¦èŒƒå›´: {ppi['confidence_stats']['min_combined_score']} - {ppi['confidence_stats']['max_combined_score']}")
            
            if 'evidence_analysis' in ppi:
                print(f"   è¯æ®é€šé“ä½¿ç”¨ç‡:")
                for channel, stats in ppi['evidence_analysis'].items():
                    print(f"     {channel}: {stats['non_zero_percentage']:.1f}%")
        
        # ä¸“å®¶ç»„ä¿¡æ¯
        if 'expert_groups_analysis' in report:
            ega = report['expert_groups_analysis']
            print(f"\nğŸ­ MoEä¸“å®¶ç»„:")
            print(f"   ä¸“å®¶ç»„æ•°é‡: {ega['num_experts']}")
            print(f"   è¦†ç›–è›‹ç™½è´¨: {ega['total_proteins_in_groups']:,}")
            print(f"   å¹³å‡ç»„å¤§å°: {ega['size_distribution']['mean_size']:.1f} Â± {ega['size_distribution']['std_size']:.1f}")
            print(f"   ç»„å¤§å°èŒƒå›´: {ega['size_distribution']['min_size']} - {ega['size_distribution']['max_size']}")
        
        # è¿‡æ»¤ç»Ÿè®¡
        if 'filtering_statistics' in report:
            print(f"\nğŸ“ˆ æ•°æ®è¿‡æ»¤æ•ˆæœ:")
            fs = report['filtering_statistics']
            if 'protein_filtering' in fs:
                pf = fs['protein_filtering']
                print(f"   è›‹ç™½è´¨ä¿ç•™ç‡: {pf['retention_rate']*100:.1f}%")
            if 'ppi_filtering' in fs:
                ppif = fs['ppi_filtering']
                print(f"   PPIä¿ç•™ç‡: {ppif['final_retention_rate']*100:.1f}%")
        
        print("\n" + "="*80)
        print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå¯ä»¥å¼€å§‹PSSMç”Ÿæˆï¼")
        print("="*80)
    
    def save_summary_statistics(self, stats: Dict, filename: str = "summary_stats.json") -> Path:
        """ä¿å­˜æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯"""
        output_path = self.output_dir / filename
        with open(output_path, 'w') as f:
            json.dump(stats, f, indent=2, default=str)
        
        logger.info(f"æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {output_path}")
        return output_path