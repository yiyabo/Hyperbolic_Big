#!/usr/bin/env python3
"""
æµ‹è¯•PRINGæ•°æ®åŠ è½½å™¨

éªŒè¯æ•°æ®åŠ è½½å™¨çš„åŠŸèƒ½å’Œæ€§èƒ½
"""

import sys
sys.path.append('.')

import time
import logging
from data_loader import PRINGPairDataset, PRINGGraphDataset, PRINGConfig, get_dataloader

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_config():
    """æµ‹è¯•é…ç½®ç±»"""
    logger.info("="*60)
    logger.info("æµ‹è¯•1: é…ç½®ç±»")
    logger.info("="*60)
    
    # æµ‹è¯•humané…ç½®
    config = PRINGConfig(species="human", sampling_strategy="BFS", split="train")
    logger.info(f"é…ç½®åˆ›å»ºæˆåŠŸ:\n{config}")
    
    # éªŒè¯æ–‡ä»¶
    assert config.validate(), "é…ç½®éªŒè¯å¤±è´¥"
    logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
    
    # æµ‹è¯•è·¨ç‰©ç§é…ç½®
    for species in ['arath', 'yeast', 'ecoli']:
        config = PRINGConfig(species=species, split="test")
        assert config.validate(), f"{species} é…ç½®éªŒè¯å¤±è´¥"
        logger.info(f"âœ… {species} é…ç½®éªŒè¯é€šè¿‡")


def test_pair_dataset():
    """æµ‹è¯•æˆå¯¹æ•°æ®é›†"""
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯•2: PRINGPairDataset")
    logger.info("="*60)
    
    # åˆ›å»ºæ•°æ®é›†
    config = PRINGConfig(species="human", sampling_strategy="BFS", split="train")
    dataset = PRINGPairDataset(config, return_ids=True)
    
    logger.info(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = dataset.get_statistics()
    logger.info("æ•°æ®é›†ç»Ÿè®¡:")
    logger.info(f"  æ€»PPIå¯¹: {stats['num_pairs']:,}")
    logger.info(f"  è›‹ç™½è´¨æ•°: {stats['num_proteins']:,}")
    logger.info(f"  æ­£æ ·æœ¬: {stats['num_positive']:,}")
    logger.info(f"  è´Ÿæ ·æœ¬: {stats['num_negative']:,}")
    logger.info(f"  æ­£æ ·æœ¬æ¯”ä¾‹: {stats['positive_ratio']:.2%}")
    logger.info(f"  å¹³å‡åºåˆ—é•¿åº¦: {stats['avg_seq_length']:.1f}")
    logger.info(f"  åºåˆ—é•¿åº¦èŒƒå›´: [{stats['min_seq_length']}, {stats['max_seq_length']}]")
    
    # æµ‹è¯•æ ·æœ¬è®¿é—®
    sample = dataset[0]
    logger.info(f"\næ ·æœ¬ç¤ºä¾‹:")
    logger.info(f"  è›‹ç™½è´¨1 ID: {sample['protein1_id']}")
    logger.info(f"  è›‹ç™½è´¨2 ID: {sample['protein2_id']}")
    logger.info(f"  åºåˆ—1é•¿åº¦: {len(sample['seq1'])}")
    logger.info(f"  åºåˆ—2é•¿åº¦: {len(sample['seq2'])}")
    logger.info(f"  åºåˆ—1å‰50å­—ç¬¦: {sample['seq1'][:50]}...")
    logger.info(f"  æ ‡ç­¾: {sample['label']}")
    
    logger.info("âœ… PRINGPairDataset æµ‹è¯•é€šè¿‡")
    return dataset


def test_dataloader(dataset):
    """æµ‹è¯•DataLoader"""
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯•3: DataLoader")
    logger.info("="*60)
    
    # åˆ›å»ºDataLoader
    dataloader = get_dataloader(
        dataset,
        batch_size=8,
        shuffle=True,
        num_workers=0  # æµ‹è¯•æ—¶ä½¿ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
    )
    
    logger.info(f"DataLoader batchæ•°: {len(dataloader)}")
    
    # éå†ä¸€ä¸ªbatch
    start_time = time.time()
    for i, batch in enumerate(dataloader):
        if i == 0:  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªbatch
            logger.info(f"\nBatchç¤ºä¾‹:")
            logger.info(f"  seq1ç±»å‹: {type(batch['seq1'])}")
            logger.info(f"  seq1é•¿åº¦: {len(batch['seq1'])}")
            logger.info(f"  seq2é•¿åº¦: {len(batch['seq2'])}")
            logger.info(f"  labels: {batch['label']}")
            logger.info(f"  labelsç±»å‹: {type(batch['label'])}")
            
        if i >= 2:  # åªæµ‹è¯•å‰3ä¸ªbatch
            break
    
    elapsed = time.time() - start_time
    logger.info(f"âœ… DataLoader æµ‹è¯•é€šè¿‡ (è€—æ—¶: {elapsed:.2f}s)")


def test_graph_dataset():
    """æµ‹è¯•å›¾æ•°æ®é›†"""
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯•4: PRINGGraphDataset")
    logger.info("="*60)
    
    try:
        # æµ‹è¯•all_testæ•°æ®
        config = PRINGConfig(species="human", sampling_strategy="BFS", split="all_test")
        dataset = PRINGGraphDataset(config, load_graph=True)
        
        logger.info(f"å›¾æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # è·å–æ‰€æœ‰è›‹ç™½è´¨
        all_proteins = dataset.get_all_proteins()
        logger.info(f"æµ‹è¯•å›¾ä¸­è›‹ç™½è´¨æ•°: {len(all_proteins)}")
        
        if dataset.ground_truth_graph is not None:
            logger.info(f"çœŸå®å›¾èŠ‚ç‚¹æ•°: {dataset.ground_truth_graph.number_of_nodes()}")
            logger.info(f"çœŸå®å›¾è¾¹æ•°: {dataset.ground_truth_graph.number_of_edges()}")
        
        # æµ‹è¯•æ ·æœ¬
        sample = dataset[0]
        logger.info(f"\nå›¾æ•°æ®æ ·æœ¬:")
        logger.info(f"  è›‹ç™½è´¨1: {sample['protein1_id']}")
        logger.info(f"  è›‹ç™½è´¨2: {sample['protein2_id']}")
        logger.info(f"  æ ‡ç­¾: {sample['label']}")
        
        logger.info("âœ… PRINGGraphDataset æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        logger.warning(f"âš ï¸  PRINGGraphDataset æµ‹è¯•è·³è¿‡: {e}")


def test_cross_species():
    """æµ‹è¯•è·¨ç‰©ç§æ•°æ®åŠ è½½"""
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯•5: è·¨ç‰©ç§æ•°æ®é›†")
    logger.info("="*60)
    
    species_list = ['arath', 'yeast', 'ecoli']
    
    for species in species_list:
        try:
            config = PRINGConfig(species=species, split="test")
            dataset = PRINGPairDataset(config)
            
            stats = dataset.get_statistics()
            logger.info(f"\n{species.upper()}:")
            logger.info(f"  PPIå¯¹: {stats['num_pairs']:,}")
            logger.info(f"  è›‹ç™½è´¨æ•°: {stats['num_proteins']:,}")
            logger.info(f"  å¹³å‡åºåˆ—é•¿åº¦: {stats['avg_seq_length']:.1f}")
            
        except Exception as e:
            logger.error(f"âŒ {species} æµ‹è¯•å¤±è´¥: {e}")
    
    logger.info("\nâœ… è·¨ç‰©ç§æµ‹è¯•å®Œæˆ")


def test_sampling_strategies():
    """æµ‹è¯•ä¸åŒé‡‡æ ·ç­–ç•¥"""
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯•6: é‡‡æ ·ç­–ç•¥å¯¹æ¯”")
    logger.info("="*60)
    
    strategies = ['BFS', 'DFS', 'RANDOM_WALK']
    
    for strategy in strategies:
        try:
            config = PRINGConfig(
                species="human",
                sampling_strategy=strategy,
                split="train"
            )
            dataset = PRINGPairDataset(config)
            stats = dataset.get_statistics()
            
            logger.info(f"\n{strategy}:")
            logger.info(f"  PPIå¯¹: {stats['num_pairs']:,}")
            logger.info(f"  æ­£æ ·æœ¬æ¯”ä¾‹: {stats['positive_ratio']:.2%}")
            
        except Exception as e:
            logger.error(f"âŒ {strategy} æµ‹è¯•å¤±è´¥: {e}")
    
    logger.info("\nâœ… é‡‡æ ·ç­–ç•¥æµ‹è¯•å®Œæˆ")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•PRINGæ•°æ®åŠ è½½å™¨\n")
    
    try:
        # æµ‹è¯•é…ç½®
        test_config()
        
        # æµ‹è¯•æˆå¯¹æ•°æ®é›†
        dataset = test_pair_dataset()
        
        # æµ‹è¯•DataLoader
        test_dataloader(dataset)
        
        # æµ‹è¯•å›¾æ•°æ®é›†
        test_graph_dataset()
        
        # æµ‹è¯•è·¨ç‰©ç§
        test_cross_species()
        
        # æµ‹è¯•é‡‡æ ·ç­–ç•¥
        test_sampling_strategies()
        
        logger.info("\n" + "="*60)
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®åŠ è½½å™¨å°±ç»ª")
        logger.info("="*60)
        
        return True
        
    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

