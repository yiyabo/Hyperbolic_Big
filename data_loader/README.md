# PRINGæ•°æ®åŠ è½½å™¨ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æä¾›æ ‡å‡†åŒ–çš„PyTorch Datasetç±»ï¼Œç”¨äºåŠ è½½å’Œå¤„ç†PRINGåŸºå‡†æµ‹è¯•æ•°æ®ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from data_loader import PRINGPairDataset, PRINGConfig, get_dataloader

# 1. åˆ›å»ºé…ç½®
config = PRINGConfig(
    species="human",
    sampling_strategy="BFS",
    split="train"
)

# 2. åˆ›å»ºæ•°æ®é›†
dataset = PRINGPairDataset(config)

# 3. åˆ›å»ºDataLoader
dataloader = get_dataloader(dataset, batch_size=32, shuffle=True)

# 4. éå†æ•°æ®
for batch in dataloader:
    seq1 = batch['seq1']  # List[str]
    seq2 = batch['seq2']  # List[str]
    labels = batch['label']  # torch.Tensor
    
    # ä½ çš„è®­ç»ƒä»£ç ...
```

### æ•°æ®é›†ç»Ÿè®¡

```python
# æŸ¥çœ‹æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
stats = dataset.get_statistics()
print(f"æ€»PPIå¯¹: {stats['num_pairs']}")
print(f"è›‹ç™½è´¨æ•°: {stats['num_proteins']}")
print(f"æ­£æ ·æœ¬æ¯”ä¾‹: {stats['positive_ratio']:.2%}")
print(f"å¹³å‡åºåˆ—é•¿åº¦: {stats['avg_seq_length']:.1f}")
```

## ğŸ¯ æ”¯æŒçš„é…ç½®

### ç‰©ç§ (species)
- `"human"` - äººç±»ï¼ˆè®­ç»ƒé›†ï¼‰
- `"arath"` - æ‹Ÿå—èŠ¥ï¼ˆæµ‹è¯•é›†ï¼‰
- `"yeast"` - é…µæ¯ï¼ˆæµ‹è¯•é›†ï¼‰
- `"ecoli"` - å¤§è‚ æ†èŒï¼ˆæµ‹è¯•é›†ï¼‰

### é‡‡æ ·ç­–ç•¥ (sampling_strategy)
ä»…å¯¹humanæœ‰æ•ˆï¼š
- `"BFS"` - å¹¿åº¦ä¼˜å…ˆæœç´¢ï¼ˆæ¨èï¼‰
- `"DFS"` - æ·±åº¦ä¼˜å…ˆæœç´¢
- `"RANDOM_WALK"` - éšæœºæ¸¸èµ°

### æ•°æ®åˆ‡åˆ† (split)
- `"train"` - è®­ç»ƒé›†ï¼ˆä»…humanï¼‰
- `"val"` - éªŒè¯é›†ï¼ˆä»…humanï¼‰
- `"test"` - æµ‹è¯•é›†ï¼ˆäºŒåˆ†ç±»è¯„ä¼°ï¼‰
- `"all_test"` - å®Œæ•´æµ‹è¯•é›†ï¼ˆå›¾é‡å»ºè¯„ä¼°ï¼‰

## ğŸ“‚ æ•°æ®è·¯å¾„é…ç½®

### æ–¹å¼1ï¼šä½¿ç”¨é»˜è®¤è·¯å¾„

```python
# è‡ªåŠ¨ä½¿ç”¨é¡¹ç›®ä¸­çš„data/PRING/...
config = PRINGConfig(species="human", split="train")
```

### æ–¹å¼2ï¼šè®¾ç½®ç¯å¢ƒå˜é‡

```bash
# åœ¨~/.bashrc æˆ– ~/.zshrc ä¸­æ·»åŠ 
export PRING_DATA_ROOT="/path/to/your/PRING/data_process/pring_dataset"
```

```python
# ä»£ç ä¸­ä¼šè‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡
config = PRINGConfig(species="human", split="train")
```

### æ–¹å¼3ï¼šæ˜¾å¼æŒ‡å®šè·¯å¾„

```python
config = PRINGConfig(
    data_root="/custom/path/to/pring_dataset",
    species="human",
    split="train"
)
```

## ğŸ’¡ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šè®­ç»ƒæ¨¡å‹ï¼ˆäººç±»æ•°æ®ï¼‰

```python
from data_loader import PRINGPairDataset, PRINGConfig, get_dataloader

# è®­ç»ƒé›†
train_config = PRINGConfig(species="human", sampling_strategy="BFS", split="train")
train_dataset = PRINGPairDataset(train_config)
train_loader = get_dataloader(train_dataset, batch_size=32, shuffle=True)

# éªŒè¯é›†
val_config = PRINGConfig(species="human", sampling_strategy="BFS", split="val")
val_dataset = PRINGPairDataset(val_config)
val_loader = get_dataloader(val_dataset, batch_size=64, shuffle=False)

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    for batch in train_loader:
        # è®­ç»ƒä»£ç ...
        pass
    
    # éªŒè¯
    for batch in val_loader:
        # éªŒè¯ä»£ç ...
        pass
```

### åœºæ™¯2ï¼šå¿«é€Ÿè¯„ä¼°ï¼ˆäºŒåˆ†ç±»ï¼‰

```python
# æµ‹è¯•é›†
test_config = PRINGConfig(species="human", sampling_strategy="BFS", split="test")
test_dataset = PRINGPairDataset(test_config, return_ids=True)
test_loader = get_dataloader(test_dataset, batch_size=64, shuffle=False)

# è¯„ä¼°
all_preds = []
all_labels = []

for batch in test_loader:
    preds = model.predict(batch['seq1'], batch['seq2'])
    all_preds.extend(preds)
    all_labels.extend(batch['label'])

# è®¡ç®—æŒ‡æ ‡
from sklearn.metrics import roc_auc_score, average_precision_score
auc = roc_auc_score(all_labels, all_preds)
aupr = average_precision_score(all_labels, all_preds)
```

### åœºæ™¯3ï¼šå›¾é‡å»ºè¯„ä¼°ï¼ˆå®Œæ•´PRINGè¯„ä¼°ï¼‰

```python
from data_loader import PRINGGraphDataset

# ä½¿ç”¨all_testæ•°æ®
config = PRINGConfig(species="human", sampling_strategy="BFS", split="all_test")
dataset = PRINGGraphDataset(config, load_graph=True)
loader = get_dataloader(dataset, batch_size=64, shuffle=False)

# é¢„æµ‹æ‰€æœ‰è¾¹
predictions = []
for batch in loader:
    preds = model.predict(batch['seq1'], batch['seq2'])
    for i in range(len(preds)):
        predictions.append((
            batch['protein1_id'][i],
            batch['protein2_id'][i],
            int(preds[i] > 0.5)  # äºŒå€¼åŒ–
        ))

# ä¿å­˜é¢„æµ‹ç»“æœ
dataset.save_predictions(predictions, "human_BFS_all_test_ppi_pred.txt")

# è¿è¡ŒPRINGè¯„ä¼°è„šæœ¬
import subprocess
subprocess.run([
    "python", "data/PRING/topology_task/eval.py",
    "--ppi_path", "human_BFS_all_test_ppi_pred.txt",
    "--gt_graph_path", str(config.test_graph_file),
    "--test_graph_node_path", str(config.sampled_nodes_file)
])
```

### åœºæ™¯4ï¼šè·¨ç‰©ç§æ³›åŒ–æµ‹è¯•

```python
# åœ¨äººç±»æ•°æ®ä¸Šè®­ç»ƒï¼ˆåœºæ™¯1ï¼‰
# ...

# åœ¨å…¶ä»–ç‰©ç§ä¸Šæµ‹è¯•
for species in ['arath', 'yeast', 'ecoli']:
    test_config = PRINGConfig(species=species, split="all_test")
    test_dataset = PRINGGraphDataset(test_config)
    test_loader = get_dataloader(test_dataset, batch_size=64)
    
    # é¢„æµ‹å’Œè¯„ä¼°
    # ...
```

## ğŸ”§ è‡ªå®šä¹‰åºåˆ—è½¬æ¢

```python
def tokenize_sequence(seq: str) -> torch.Tensor:
    """è‡ªå®šä¹‰åºåˆ—è½¬æ¢å‡½æ•°"""
    # ä¾‹å¦‚ï¼šä½¿ç”¨ESM tokenizer
    from transformers import EsmTokenizer
    tokenizer = EsmTokenizer.from_pretrained("facebook/esm2_t6_8M_UR50D")
    return tokenizer(seq, return_tensors="pt")['input_ids']

# åœ¨æ•°æ®é›†ä¸­ä½¿ç”¨
dataset = PRINGPairDataset(config, transform=tokenize_sequence)
```

## ğŸ“Š æ•°æ®é›†ç±»

### PRINGPairDataset
ç”¨äºæˆå¯¹PPIé¢„æµ‹ï¼ˆäºŒåˆ†ç±»ä»»åŠ¡ï¼‰

**ç‰¹ç‚¹**ï¼š
- è¿”å›åºåˆ—å¯¹å’Œæ ‡ç­¾
- æ”¯æŒè‡ªå®šä¹‰è½¬æ¢å‡½æ•°
- å†…ç½®åºåˆ—é•¿åº¦è¿‡æ»¤
- æä¾›æ•°æ®ç»Ÿè®¡

**è¿”å›æ ¼å¼**ï¼š
```python
{
    'seq1': str,          # ç¬¬ä¸€ä¸ªè›‹ç™½è´¨åºåˆ—
    'seq2': str,          # ç¬¬äºŒä¸ªè›‹ç™½è´¨åºåˆ—
    'label': int,         # æ ‡ç­¾ (0æˆ–1)
    'protein1_id': str,   # ID (å¯é€‰)
    'protein2_id': str    # ID (å¯é€‰)
}
```

### PRINGGraphDataset
ç”¨äºå›¾é‡å»ºä»»åŠ¡

**ç‰¹ç‚¹**ï¼š
- åŠ è½½all-against-allæµ‹è¯•å¯¹
- è‡ªåŠ¨åŠ è½½çœŸå®å›¾ç»“æ„
- æä¾›é¢„æµ‹ç»“æœä¿å­˜åŠŸèƒ½
- æ”¯æŒPRINGè¯„ä¼°è„šæœ¬

**é¢å¤–æ–¹æ³•**ï¼š
- `get_all_proteins()` - è·å–æ‰€æœ‰è›‹ç™½è´¨ID
- `save_predictions()` - ä¿å­˜é¢„æµ‹ç»“æœä¸ºPRINGæ ¼å¼

## ğŸ” é¢„å®šä¹‰é…ç½®

å¿«é€Ÿä½¿ç”¨å¸¸è§é…ç½®ï¼š

```python
from data_loader.config import (
    HUMAN_TRAIN_BFS,
    HUMAN_VAL_BFS,
    HUMAN_TEST_BFS,
    ARATH_TEST,
    YEAST_TEST,
    ECOLI_TEST
)

# ç›´æ¥ä½¿ç”¨
train_dataset = PRINGPairDataset(HUMAN_TRAIN_BFS)
```

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶

```python
# æ£€æŸ¥é…ç½®
config = PRINGConfig(species="human", split="train")
print(config)

# éªŒè¯æ–‡ä»¶
if not config.validate():
    print("æ•°æ®æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
```

### é—®é¢˜2ï¼šåºåˆ—ç¼ºå¤±

æ•°æ®åŠ è½½å™¨ä¼šè‡ªåŠ¨è¿‡æ»¤ç¼ºå°‘åºåˆ—çš„PPIå¯¹ï¼Œå¹¶æ˜¾ç¤ºè­¦å‘Šã€‚

### é—®é¢˜3ï¼šè·¯å¾„é—®é¢˜ï¼ˆæœ¬åœ° vs æœåŠ¡å™¨ï¼‰

```python
# æ–¹æ³•1ï¼šç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰
# æœåŠ¡å™¨ä¸Šè®¾ç½®ï¼šexport PRING_DATA_ROOT="/data/pring/..."

# æ–¹æ³•2ï¼šä»£ç ä¸­åŠ¨æ€åˆ¤æ–­
import os
if os.path.exists("/server/data/PRING"):
    data_root = "/server/data/PRING/data_process/pring_dataset"
else:
    data_root = None  # ä½¿ç”¨é»˜è®¤è·¯å¾„
```

## ğŸ“ˆ æ€§èƒ½å»ºè®®

- **num_workers**: å»ºè®®è®¾ç½®ä¸º4-8ï¼Œæ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
- **batch_size**: æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´ï¼ŒESM-2æ¨è32-64
- **åºåˆ—é•¿åº¦**: é»˜è®¤é™åˆ¶1000ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [PRINGæ•°æ®é›†å®Œæ•´æ–‡æ¡£](../docs/pring_dataset.md)
- [PRINGå®˜æ–¹ä»“åº“](https://github.com/SophieSarceau/PRING)
- [PRINGè®ºæ–‡](https://arxiv.org/abs/2507.05101)

